{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiKnE8nB5vGM"
      },
      "source": [
        "### INFO284 Machine Learning Exam, spring 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9Bv9uf39YK_"
      },
      "source": [
        "#### Importing and versioncontrol for relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi0O1bxI9KEG",
        "outputId": "34b6ddad-ba8d-4810-efd0-c55602412e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python version: 3.12.2 (tags/v3.12.2:6abddd9, Feb  6 2024, 21:26:36) [MSC v.1937 64 bit (AMD64)]\n",
            "pandas version: 2.2.1\n",
            "matplotlib version: 3.8.3\n",
            "NumPy version: 1.26.4\n",
            "SciPy version: 1.12.0\n",
            "IPython version: 8.21.0\n",
            "scikit-learn version: 1.4.1.post1\n",
            "seaborn version: 0.13.2\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(\"Python version: {}\".format(sys.version))\n",
        "import pandas as pd\n",
        "print(\"pandas version: {}\".format(pd.__version__))\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "print(\"matplotlib version: {}\".format(matplotlib.__version__))\n",
        "import numpy as np\n",
        "print(\"NumPy version: {}\".format(np.__version__))\n",
        "import scipy as sp\n",
        "print(\"SciPy version: {}\".format(sp.__version__))\n",
        "import IPython\n",
        "print(\"IPython version: {}\".format(IPython.__version__))\n",
        "import sklearn\n",
        "print(\"scikit-learn version: {}\".format(sklearn.__version__))\n",
        "import seaborn as sns\n",
        "print(\"seaborn version: {}\".format(sns.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYRuts8B-ITy"
      },
      "source": [
        "#### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "dHNDvOovwmBw",
        "outputId": "993d640c-7f2d-442f-ee03-7bbb9e05380d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before pre-processing the dataset has 45 columns and 305434 rows\n"
          ]
        }
      ],
      "source": [
        "filePath = 'elektronisk-rapportering-ers-2018-fangstmelding-dca-simple.csv'\n",
        "# Keep in mind that the file is encoded in UTF-8 so it will only work if you have the correct version of pandas.\n",
        "df = pd.read_csv(filePath, encoding=\"UTF-8\" , delimiter=\";\")\n",
        "print(f\"Before pre-processing the dataset has {df.shape[1]} columns and {df.shape[0]} rows\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw5rbR1t-fTc"
      },
      "source": [
        "#### Chosing target and pre-prossesing\n",
        "After taking some time to understand the data we have chosen our target features to be the catches of Hyse, Torsk and Sei as continuous values. Next we will pre-prosess the data so it is ready for modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using the same seed for testing purposes makes the results more comparable\n",
        "seed = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Excluding irrelevant columns\n",
        "\n",
        "# Fangstår has only 2 unique values\n",
        "df.drop(columns = ['Fangstår'], inplace= True)\n",
        "\n",
        "# Lengdegruppe (kode), Lengdegruppe, Bruttotonnasje 1969, Bruttotonnasje annen, Bredde, Fartøylengde all seem to be speaking of the boat doing the catching, with few unique values in each column.\n",
        "# One of them should be kept as a feature, the rest discarded. We would suggest the most relevant to be Bruttotonasje, which speaks to how much cargo space there is.\n",
        "# \"Bruttotonnasje 1969\" and \"Bruttotonnasje annen\" seem to have nan where the other one has a value, so first we will collapse them into one.\n",
        "df['Bruttotonnasje'] = df['Bruttotonnasje annen'].combine_first(df['Bruttotonnasje 1969'])\n",
        "df.drop(columns=['Bruttotonnasje annen', \"Bruttotonnasje 1969\",\"Lengdegruppe (kode)\", \"Lengdegruppe\", \"Bredde\", \"Fartøylengde\"], inplace=True)\n",
        "\n",
        "# All columns (kode) in them are cateogrical code representations of another column. For human-readability and to avoid mistaking the code for a continuous value we will remove them.\n",
        "df.drop(columns=[\"Hovedområde start (kode)\", \"Lokasjon start (kode)\", \"Hovedområde stopp (kode)\", \"Lokasjon stopp (kode)\", \"Redskap FAO (kode)\", \"Redskap FDIR (kode)\", \"Hovedart FAO (kode)\", \"Hovedart - FDIR (kode)\", \"Art FAO (kode)\", \"Art - FDIR (kode)\", \"Art - gruppe (kode)\", ], inplace = True)\n",
        "\n",
        "# In both the \"Redskap\" and \"Art\" columns you have FAO and FDIR abbriviations. FAO = Food and Agriculture Organization of the United Nations and FDIR = Fiskeridirektoratet\n",
        "# Due to \"Hovedart\" onyl having FAO uncoded we will stick to FAO. For the same reason we will remove \"Art - gruppe\"\n",
        "df.drop(columns=[\"Art - gruppe\", \"Art - FDIR\", \"Redskap FDIR\"], inplace=True)\n",
        "\n",
        "# While time of day and date might be relevant we don't need all of them and we don't need to know when it was reported in. For now we will leave start/end date and time.\n",
        "df.drop(columns=[\"Meldingstidspunkt\", \"Meldingsdato\", \"Meldingsklokkeslett\", \"Starttidspunkt\", \"Stopptidspunkt\"], inplace=True)\n",
        "\n",
        "# The areas where they start and stop have 6 columns. A pair of coordiantes and name of area x2. Since we prefer the continuous features and coordinates=name of place we are removing the name.\n",
        "df.drop(columns=[\"Hovedområde start\", \"Hovedområde stopp\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# After having checked to see what % of each column had nan values we decided just to drop them as at worst they were around 1.6 %\n",
        "df = df.dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Focusing down on the species we want to investigate\n",
        "# More might be added later as categories or ranges\n",
        "\n",
        "df = df[df['Art FAO'].isin(['Torsk', 'Sei', 'Hyse'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Removing parts of columns\n",
        "\n",
        "# From varighet we remove anyting above 400 as according to lecturer that is in the high range of how long you would be fishing in a session.\n",
        "# So we will consider them outliers or multiple sessions reported as one and exclude them for now.\n",
        "\n",
        "df = df[df['Varighet'] <= 400]\n",
        "\n",
        "# Maybe remove some outliers from \"Trekkavstand\". Above 50000 the frequency gets 100 instances per 5000 length.\n",
        "# Just doing it for now, unsure of necessity\n",
        "df = df[df['Trekkavstand'] <= 50000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manipulating columns\n",
        "\n",
        "# The coordinates are strings, here I'm changing them to int so they're easier to use.\n",
        "# Later we might potentially change them in a different way.\n",
        "df['Startposisjon bredde'] = df['Startposisjon bredde'].str.replace(',', '').astype(int)\n",
        "df['Startposisjon lengde'] = df['Startposisjon lengde'].str.replace(',', '').astype(int)\n",
        "df['Stopposisjon bredde'] = df['Stopposisjon bredde'].str.replace(',', '').astype(int)\n",
        "df['Stopposisjon lengde'] = df['Stopposisjon lengde'].str.replace(',', '').astype(int)\n",
        "\n",
        "# Date/time could potentially be changed to month/hour?\n",
        "# df['Startmåned'] = df['Startdato'].astype(str).str[3:5]\n",
        "# df['Starttime'] = df['Startklokkeslett'].astype(str).str[3:5]\n",
        "# df['Stoppmåned'] = df['Stoppdato'].astype(str).str[3:5]\n",
        "# df['Stopptime'] = df['Stoppklokkeslett'].astype(str).str[3:5]\n",
        "# df.drop(columns=['Startdato', \"Startklokkeslett\", \"Stoppdato\", \"Stoppklokkeslett\"], inplace=True)\n",
        "\n",
        "# Many of the sea depth notations are positiv, which doesn't make sense.\n",
        "# But the amount of them in relation to number of entries means it can't be discounted as an error\n",
        "# In the lecture on fisheries it was mentioned that a lot fo these are inputed manually\n",
        "# And that most of these non-sensical sea depths are actually correct, just lacking a minus.\n",
        "# Therefore we are simply flipping all the positive sea depth into negatives.\n",
        "df['Havdybde start'] = -df['Havdybde start'].abs()\n",
        "df['Havdybde stopp'] = -df['Havdybde stopp'].abs()\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After pre-processing the dataset has 20 columns and 51083 rows\n"
          ]
        }
      ],
      "source": [
        "# Pivoting table\n",
        "\n",
        "# Pivoting table so rows that are information about the same session are put together\n",
        "df = df.pivot_table(index=['Melding ID', 'Startdato', 'Startklokkeslett', 'Startposisjon bredde', 'Startposisjon lengde', 'Havdybde start', 'Stoppdato', 'Stoppklokkeslett', 'Varighet', 'Stopposisjon bredde', 'Stopposisjon lengde', 'Havdybde stopp', 'Trekkavstand', 'Redskap FAO', 'Hovedart FAO','Bruttotonnasje'], columns='Art FAO', values='Rundvekt', aggfunc='sum').reset_index()\n",
        "\n",
        "# This creates a lot of nan values which we fill with 0\n",
        "df = df.fillna(0)\n",
        "\n",
        "# We add another column to indicate which was the dominant catch during that session\n",
        "# Might be removed or deemed redunadant later on as it has a 86% match to \"Hovedfangst FAO\"\n",
        "df['Hovedfangst'] = df[['Hyse', 'Sei', 'Torsk']].idxmax(axis=1)\n",
        "\n",
        "print(f\"After pre-processing the dataset has {df.shape[1]} columns and {df.shape[0]} rows\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
