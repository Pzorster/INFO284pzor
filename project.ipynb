{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiKnE8nB5vGM"
      },
      "source": [
        "### INFO284 Machine Learning Exam, spring 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9Bv9uf39YK_"
      },
      "source": [
        "#### Importing and versioncontrol for relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi0O1bxI9KEG",
        "outputId": "34b6ddad-ba8d-4810-efd0-c55602412e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python version: 3.12.2 (tags/v3.12.2:6abddd9, Feb  6 2024, 21:26:36) [MSC v.1937 64 bit (AMD64)]\n",
            "pandas version: 2.2.1\n",
            "matplotlib version: 3.8.3\n",
            "NumPy version: 1.26.4\n",
            "SciPy version: 1.12.0\n",
            "IPython version: 8.21.0\n",
            "scikit-learn version: 1.4.1.post1\n",
            "seaborn version: 0.13.2\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(\"Python version: {}\".format(sys.version))\n",
        "import pandas as pd\n",
        "print(\"pandas version: {}\".format(pd.__version__))\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "print(\"matplotlib version: {}\".format(matplotlib.__version__))\n",
        "import numpy as np\n",
        "print(\"NumPy version: {}\".format(np.__version__))\n",
        "import scipy as sp\n",
        "print(\"SciPy version: {}\".format(sp.__version__))\n",
        "import IPython\n",
        "print(\"IPython version: {}\".format(IPython.__version__))\n",
        "import sklearn\n",
        "print(\"scikit-learn version: {}\".format(sklearn.__version__))\n",
        "import seaborn as sns\n",
        "print(\"seaborn version: {}\".format(sns.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYRuts8B-ITy"
      },
      "source": [
        "#### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "dHNDvOovwmBw",
        "outputId": "993d640c-7f2d-442f-ee03-7bbb9e05380d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before pre-processing the dataset has 45 columns and 305434 rows\n"
          ]
        }
      ],
      "source": [
        "filePath = 'elektronisk-rapportering-ers-2018-fangstmelding-dca-simple.csv'\n",
        "# Keep in mind that the file is encoded in UTF-8 so it will only work if you have the correct version of pandas.\n",
        "df = pd.read_csv(filePath, encoding=\"UTF-8\" , delimiter=\";\")\n",
        "print(f\"Before pre-processing the dataset has {df.shape[1]} columns and {df.shape[0]} rows\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw5rbR1t-fTc"
      },
      "source": [
        "#### Step 1: chosing target and pre-prossesing\n",
        "After taking some time to understand the data we have chosen our target features to be the catches of Hyse, Torsk and Sei. Next we must pre-prosess the data into suitable forms for modeling, this might take different forms as we try different ways to model it. The **key skill** here will therefor be the ability to manipulate the pandas dataframe.\n",
        "\n",
        "Ways we might process the data:\n",
        "1. Remove uncessary columns.\n",
        "2. Collapse columns that say the same thing into one column.\n",
        "3. Remove or manipulate non-sensical or missing values.\n",
        "4. Transform values to work with our model.\n",
        "\n",
        "*Question: should we also show how we went about understanding the data?*\n",
        "\n",
        "(Old)The dataset needs a lot of pre processing. Current objective is to clean and remove redundancy and irrelevant columns. In this step we are actively discussing what our goal will be machine learning model, while understanding the data on a deeper level"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG5nZmsgKbSI"
      },
      "source": [
        "#### 1.1: First purge of redundancy\n",
        "In this step we will do an intial transformation of the data which will be applicable to all our modeling(maybe?).\n",
        "\n",
        "We might also set up functions for more complicated manipulations?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Excluding irrelevant columns\n",
        "df = df[['Melding ID','Art - gruppe','Meldingsdato','Starttidspunkt','Havdybde start','Havdybde stopp','Rundvekt', 'Hovedområde start', 'Hovedart FAO']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melding ID           0.000000\n",
            "Art - gruppe         1.631122\n",
            "Meldingsdato         0.000000\n",
            "Starttidspunkt       0.000000\n",
            "Havdybde start       0.000000\n",
            "Havdybde stopp       0.000000\n",
            "Rundvekt             1.629812\n",
            "Hovedområde start    1.350210\n",
            "Hovedart FAO         1.629812\n",
            "dtype: float64\n",
            "Current amount of rows: 296664\n"
          ]
        }
      ],
      "source": [
        "# Calculating the percentage of NaNs for each column to see whether we can afford to drop them\n",
        "nanPercentage = df.isna().mean() * 100\n",
        "print(nanPercentage)\n",
        "df = df.dropna()\n",
        "print(\"Current amount of rows: \" + str(df.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collapsing certain columns?\n",
        "#\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Many of the sea depth notations are positiv, which doesn't make sense.\n",
        "# But the amount of them in relation to number of entries means it can't be discounted as an error\n",
        "# In the lecture on fisheries it was mentioned that a lot fo these are inputed manually\n",
        "# And that most of these non-sensical sea depths are actually correct, just lacking a minus.\n",
        "# Therefore we are simply flipping all the positive sea depth into negatives.\n",
        "df['Havdybde start'] = -df['Havdybde start'].abs()\n",
        "df['Havdybde stopp'] = -df['Havdybde stopp'].abs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1.2: Pre-prosseing for test 1\n",
        "Here we will attempt to use a KNN model to predict what the main catch of each fishing trip ended up being. First we will look at the data we have."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(296664, 9)\n",
            "(137339, 9)\n",
            "(65107, 10)\n",
            "Current amount of rows: 65107\n",
            "(65107, 11)\n"
          ]
        }
      ],
      "source": [
        "print(df.shape)\n",
        "df = df[df['Art - gruppe'].isin(['Torsk', 'Sei', 'Hyse'])]\n",
        "print(df.shape)\n",
        "df = df.pivot_table(index=['Melding ID', 'Meldingsdato', 'Starttidspunkt', 'Havdybde start', 'Havdybde stopp','Hovedområde start', 'Hovedart FAO'], columns='Art - gruppe', values='Rundvekt', aggfunc='sum').reset_index()\n",
        "df = df.fillna(0) # filling Nan values with 0\n",
        "print(df.shape)\n",
        "df['Dominant Art'] = df[['Hyse', 'Sei', 'Torsk']].idxmax(axis=1)\n",
        "print(\"Current amount of rows: \" + str(df.shape[0]))\n",
        "print(df.shape)\n",
        "# sns.scatterplot(x='Havdybde start', y='Havdybde stopp', data=df, hue='Art - gruppe')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2: Testing KNN"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
